{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Baselines\n",
    "\n",
    "This notebook runs the OpenAI model baselines on the Only Connect dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt\n",
    "# %pip install guidance\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import guidance\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, you will need to add your OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load a copy of the Only Connect dataset using the [HuggingFace Datasets Library](https://huggingface.co/docs/datasets/index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"train\": \"dataset/train.json\",\n",
    "        \"validation\": \"dataset/validation.json\",\n",
    "        \"test\": \"dataset/test.json\",\n",
    "    },\n",
    "    field=\"dataset\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, load the helper function with will make the calls to the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_openai(\n",
    "    dataset,\n",
    "    task: str = \"task1\",\n",
    "    model: str = \"gpt-3.5-turbo\",\n",
    "    split: str = \"test\",\n",
    "    num_in_context_examples: int = 3,\n",
    "    dry_run: bool = False,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    guidance.llm = guidance.llms.OpenAI(model)\n",
    "\n",
    "    if task == \"task1\":\n",
    "        prompt = guidance(\n",
    "            \"\"\"{{#system~}}You are currently competing in Round 3: Connecting Wall on the quiz show Only Connect. Your task: given 16 \"clues\" (words or phrases), solve the wall by grouping the clues into four groups of four. You will be given the clues as a list. You are also given examples of solved walls, which include the connections. Provide your answer as a list of four groups of four clues; separate groups by newlines and clues by commas. Do not try to guess the connection; only use the clues given and don't make up your own.\n",
    "\n",
    "Be careful! Connecting Wall is deliberately difficult. The puzzles are designed to include red herrings and to suggest more connections than actually exist. Some clues appear to fit into more than one category. Still, there is only one perfect solution for each wall.\n",
    "{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "{{examples}}\n",
    "\n",
    "Clues: {{#each clues}} {{this}}{{#unless @last}},{{/unless}}{{/each}}\n",
    "{{~/user}}\n",
    "\n",
    "Solved wall: \n",
    "\n",
    "{{#assistant~}}{{gen 'predicted_groups' temperature=0.0 max_tokens=64}}{{~/assistant}}\n",
    "    \"\"\"\n",
    "        )\n",
    "    elif task == \"task2\":\n",
    "        prompt = guidance(\n",
    "            \"\"\"{{#system~}}You are currently competing in Round 3: Connecting Wall on the quiz show Only Connect. Your task: given 4 groups of 4 \"clues\" (words or phrases), determine the connection for each group. You will be given the groups as four lists of four. You are also given examples of solved walls, which include the connections. Provide your answer by repeating the four groups and adding \"Connection: \"{{~/system}}\n",
    "\n",
    "{{#user~}}\n",
    "{{examples}}\n",
    "\n",
    "Groups:\n",
    "{{#each groups}}{{this}}{{#unless @last}}\\n{{/unless}}{{/each}}\n",
    "{{~/user}}\n",
    "\n",
    "Solved wall: \n",
    "\n",
    "{{#assistant~}}{{gen 'predicted_connections' temperature=0.0 max_tokens=128}}{{~/assistant}}\n",
    "    \"\"\"\n",
    "        )\n",
    "\n",
    "    # Set the RNG here so repeated calls to this function will return the same results\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # Create the in-context examples\n",
    "    ic_examples = \"\"\n",
    "    random_examples = rng.sample(dataset[\"train\"][\"groups\"], k=num_in_context_examples)\n",
    "    for i, example in enumerate(random_examples):\n",
    "        ic_examples += f\"Example {i+1}\\n\"\n",
    "        for group in example.values():\n",
    "            ic_examples += \", \".join(group[\"gt_words\"]) + f\". Connection: {group['gt_connection']}\\n\"\n",
    "        ic_examples += \"\\n\"\n",
    "    ic_examples = ic_examples.strip()\n",
    "\n",
    "    # Run the model on each wall\n",
    "    for wall in dataset[split]:\n",
    "        # Clues have already been shuffled, so we can take them as is\n",
    "        wall_id, clues = (\n",
    "            wall[\"wall_id\"],\n",
    "            wall[\"words\"],\n",
    "        )\n",
    "        groups = [\", \".join(group[\"gt_words\"]) for group in wall[\"groups\"].values()]\n",
    "        # Try to parse the model response, but if it fails, just use a random guess\n",
    "        predicted_groups, predicted_connections = None, None\n",
    "        if task == \"task1\":\n",
    "            response = prompt(examples=ic_examples, clues=clues)\n",
    "            try:\n",
    "                predicted_groups = [\n",
    "                    [word.strip() for word in line.split(\",\")] for line in response[\"predicted_groups\"].splitlines()\n",
    "                ]\n",
    "            except:\n",
    "                Warning(\n",
    "                    f\"Failed to parse model response:\\n\\n{response['predicted_groups']}\\n\\nUsing random guess instead.\"\n",
    "                )\n",
    "                predicted_groups = [clues[i : i + 4] for i in range(0, len(clues), 4)]\n",
    "        else:\n",
    "            response = prompt(examples=ic_examples, groups=groups)\n",
    "            predicted_connections = [\n",
    "                re.search(r\"Connection:\\s*(.*)\", connection)\n",
    "                for connection in response[\"predicted_connections\"].splitlines()\n",
    "            ]\n",
    "            predicted_connections = [\n",
    "                connection.group(1).strip() if connection else \"\" for connection in predicted_connections\n",
    "            ]\n",
    "\n",
    "        predictions.append(\n",
    "            {\n",
    "                \"wall_id\": wall_id,\n",
    "                \"predicted_groups\": predicted_groups,\n",
    "                \"predicted_connections\": predicted_connections,\n",
    "            }\n",
    "        )\n",
    "        if dry_run:\n",
    "            print(\"--dry-run flag passed. Exiting after one example.\")\n",
    "            break\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Solving Walls\n",
    "\n",
    "To run task 1 (solving the wall), run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dry-run when you are ready to run the full dataset\n",
    "predictions = run_openai(dataset, task=\"task1\", num_in_context_examples=5, dry_run=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the predictions, save them to disk and run the evaluation script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"predictions_task1.json\").write_text(json.dumps(predictions, ensure_ascii=False, indent=2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py \\\n",
    "    --prediction_file \"./predictions_task1.json\" \\\n",
    "    --dataset_path \"./dataset/\" \\\n",
    "    --results_path \"./results_task1.json\" "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Making Connections\n",
    "\n",
    "To run task 2 (predicting the connections between solved groups), run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dry-run when you are ready to run the full dataset\n",
    "predictions = run_openai(dataset, task=\"task2\", num_in_context_examples=5, dry_run=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the predictions similarly to task 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"predictions_task2.json\").write_text(json.dumps(predictions, ensure_ascii=False, indent=2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate.py \\\n",
    "    --prediction_file \"./predictions_task2.json\" \\\n",
    "    --dataset_path \"./dataset/\" \\\n",
    "    --results_path \"./results_task2.json\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "only-connect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
